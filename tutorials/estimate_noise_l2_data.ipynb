{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc1b5540-63dc-478b-830e-a904b320a349",
   "metadata": {},
   "source": [
    "How to estimate noise in High-Frequency radar radial measurements\n",
    "===================\n",
    "\n",
    "This tutuorial shows how to estimate noise from High-Freuency data. It reproduces the calculations and figures of the paper:\n",
    "\n",
    "* Jordi Isern-Fontanet, Lucía Quirós-Collazos, Jordi Iglesias, Justino. Martínez, Joaquim Ballabrera-Poy, Jaume García-Theatre, Cristina González-Haro and Emili García-Ladona (2026). **Data-Driven Noise Estimation for Individual High-Frequency Radar Stations**. Submitted to *J. Atmos. Oceanic Technol.*\n",
    "\n",
    "This turtorial uses the dataset:\n",
    "\n",
    "* Lucía Quirós-Collazos, Jordi Isern-Fontanet, Jordi Iglesias, Justino. Martínez, Joaquim Ballabrera-Poy, Jaume García-Theatre, Cristina González-Haro and Emili García-Ladona (2025). **Radial velocities for noise estimation of ICATMAR HF radar stations (v1.0)** https://doi.org/10.20350/digitalCSIC/17704"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44320381-a07c-453e-bd16-f75a26899c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System modules\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "# Import scientific modules\n",
    "\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Graphical packages\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "from cartopy.feature import NaturalEarthFeature, COLORS\n",
    "\n",
    "# Import the toosl for estimating noise\n",
    "\n",
    "# Add the path to the package if it is not already in PYTHONPATH\n",
    "\n",
    "sys.path.append(os.sep.join(os.getcwd().split(os.sep)[:-1]) + os.sep)\n",
    "from hfradar import hfr_noise, lmercator, hfr_rmse_pairs, hfr_rmse_model, hfr_rmse_fit\n",
    "\n",
    "# Each time a module is modified it is releaded\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Inline ploting\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de069130-4c09-4dec-be55-fb6d8a867434",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "\n",
    "Set the parameters necessary to run the notebook. Download the data set from https://doi.org/10.20350/digitalCSIC/17704 and modify `datapath` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c566294c-61e9-4c75-929b-3451f425c1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath = '/Users/jisern/Recerca/Data/Radar/L2B/'\n",
    "figspath = 'figures'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f692c1-48e4-4ee1-bc0a-0890e9e97932",
   "metadata": {},
   "source": [
    "Physical parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b5397f2-4dfa-47d7-9723-dbef2111bef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmin = 10              # Minimum number of points to be used in computing RMSE\n",
    "rmin = 0               # Minimum range used in computing RMSE [km]\n",
    "rmax = 100             # Maximum range used in computing RMSE [km]\n",
    "maxdist = 500          # Maximum distance used to identify pairs [m]\n",
    "example_stat = 'GNST'  # Station used for examples\n",
    "iexample = 10          # Index of the day used as an example\n",
    "\n",
    "# Define the twio sub-networks\n",
    "\n",
    "networks = [['CREU', 'BEGU'], ['AREN', 'PBCN', 'GNST']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792bb026-f281-4da3-910d-392a05366b36",
   "metadata": {},
   "source": [
    "Graphical parmeters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356ebcc0-869b-4b7a-8654-a530ce12927c",
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 4\n",
    "height = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88729b8-d68f-49c0-9293-7dc7ce766179",
   "metadata": {},
   "source": [
    "Graphical information and objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a218d66-55a3-49c1-aa40-16ed4486c3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default color cycle\n",
    "\n",
    "refcolors = plt.rcParams['axes.prop_cycle'].by_key()['color']\n",
    "\n",
    "# Land mask for maps\n",
    "\n",
    "land = NaturalEarthFeature(category='physical',\n",
    "                           name='land',\n",
    "                           scale='10m',\n",
    "                           facecolor=COLORS['land'])\n",
    "# Ocean mask for maps\n",
    "\n",
    "ocean = NaturalEarthFeature(category='physical',\n",
    "                            name='ocean',\n",
    "                            scale='10m',\n",
    "                            facecolor=COLORS['water'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b315ec94-630b-4efa-a9f3-e31c39472029",
   "metadata": {},
   "source": [
    "# Load and prepare the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eccd25d9-92da-459d-b987-2d2b271f2951",
   "metadata": {},
   "source": [
    "Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c5d7a63-ab30-4eaa-95ca-4e3150e2b276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data:\n",
      "-- /Users/jisern/Recerca/Data/Radar/L2B/RDLm_PBCN_20231201_20250529_l2b.nc\n",
      "-- /Users/jisern/Recerca/Data/Radar/L2B/RDLm_AREN_20231201_20250529_l2b.nc\n",
      "-- /Users/jisern/Recerca/Data/Radar/L2B/RDLm_GNST_20231201_20250529_l2b.nc\n",
      "-- /Users/jisern/Recerca/Data/Radar/L2B/RDLm_CREU_20230501_20250529_l2b.nc\n",
      "-- /Users/jisern/Recerca/Data/Radar/L2B/RDLm_BEGU_20230401_20250529_l2b.nc\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "hfrdata = {}              # Radar data\n",
    "\n",
    "print('Loading data:')\n",
    "\n",
    "for file in glob.glob(datapath + 'RDLm_????_*l2b.nc'):\n",
    "\n",
    "    # Get the station name\n",
    "\n",
    "    print('--', file)\n",
    "\n",
    "    # Read the data\n",
    "\n",
    "    ds = xr.open_dataset(file, engine=\"netcdf4\")\n",
    "\n",
    "    # Get information about the stations\n",
    "\n",
    "    site = ds.attrs['Site'][:4]\n",
    "\n",
    "    res = ds.attrs['Origin'].split(' ')\n",
    "    lat0 = float(res[0])\n",
    "    lon0 = float(res[-1])\n",
    "    \n",
    "    # Input files only has lat/lon when there were measurents. Extract all possible lat/lon. Data\n",
    "    # gaps contain nan\n",
    "\n",
    "    lon = ds['lon'].mean(dim='time')\n",
    "    lat = ds['lat'].mean(dim='time')\n",
    "\n",
    "    # Remove unused variables and those that will be modifued (lat/lon)\n",
    "\n",
    "    ds = ds.drop_vars(['lon', 'lat', 'Q201', 'Q202', 'Q203', 'Q204', 'Q205', 'Q206', 'Q207', \n",
    "                       'VELU', 'VELV', 'VFLG', 'SPRC', 'HEAD', 'ETMP', 'ESPC', 'ERTC', \n",
    "                       'ERSC', 'EDTP', 'EASN', 'MAXV', 'MINV', 'XDST', 'YDST'])\n",
    "\n",
    "    # Substitute lat/lon in the dataset by the new values\n",
    "\n",
    "    ds.coords['lon'] = lon\n",
    "    ds.coords['lat'] = lat\n",
    "\n",
    "    # Number of observations at each range/bearing using the Primary Flag ('PRIM').\n",
    "\n",
    "    count = xr.zeros_like(ds['PRIM'], dtype=int)\n",
    "    count.data[ds['PRIM'].data == 1] = 1\n",
    "    ds['nobs'] = count\n",
    "    ds['nobs'].attrs[\"long_name\"] = 'Number of observations'\n",
    "\n",
    "    # Update attributes\n",
    "\n",
    "    ds.attrs['Input_file'] = file\n",
    "    ds.attrs['Site'] = site\n",
    "    ds.attrs['lon0'] = lon0\n",
    "    ds.attrs['lat0'] = lat0\n",
    "    \n",
    "    # Save the data\n",
    "\n",
    "    hfrdata.update({site:ds})\n",
    "    \n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c012235f-b2cb-4354-829f-ef0942483a1e",
   "metadata": {},
   "source": [
    "Compute distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c8f20f5-e5c0-4f38-ab7a-f923593d90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the mean lat/lon\n",
    "\n",
    "lon0 = []\n",
    "lat0 = []\n",
    "for site in hfrdata:\n",
    "    lon0.append(hfrdata[site].attrs['lon0'])\n",
    "    lat0.append(hfrdata[site].attrs['lat0'])\n",
    "lon0 = np.mean(lon0)\n",
    "lat0 = np.mean(lat0)\n",
    "\n",
    "# Mercator projection of positions\n",
    "\n",
    "for site in hfrdata:\n",
    "    lon = hfrdata[site]['lon']\n",
    "    lat = hfrdata[site]['lat']\n",
    "    x, y = lmercator(lon, lat, lon0=lon0, lat0=lat0)\n",
    "    hfrdata[site].coords['x'] = x * 1e-3\n",
    "    hfrdata[site].coords['y'] = y * 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34658515-db3d-40ca-a1c5-512638b70d0f",
   "metadata": {},
   "source": [
    "Sort sites starting from the northrenmost one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8be30867-0043-45ec-9054-292afa398301",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfrsites = []           # List of available sites sorted from North to south\n",
    "\n",
    "# Extract the location of the station\n",
    "\n",
    "dummy = []\n",
    "for site in hfrdata.keys():\n",
    "    dummy.append(hfrdata[site].attrs['lat0'])\n",
    "    hfrsites.append(site)\n",
    "\n",
    "# Convert to numpy arrays and sort\n",
    "\n",
    "index = np.argsort(dummy)[::-1]\n",
    "hfrsites = np.array(hfrsites)[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6384fc5b-ca7e-4d93-813f-eb5571a14b0c",
   "metadata": {},
   "source": [
    "Assign colors to each site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d379463-1d9c-4f4d-b495-3d93e6e3df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfrcolors = {}           # Colors for each HFR station\n",
    "\n",
    "for i, site in enumerate(hfrsites):\n",
    "    hfrcolors.update({site: refcolors[i]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85447e4c-cbaa-46db-afcd-30174a038325",
   "metadata": {},
   "source": [
    "# Estimate noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345961a4-038c-4440-b593-4ea619192d5d",
   "metadata": {},
   "source": [
    "Compute noise using the k-sigma clipping method. Daily average to reduce the size and number of data gaps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b9d8fe-e8e1-400c-a825-245ba65809a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing noise:\n",
      "-- CREU\n"
     ]
    }
   ],
   "source": [
    "hfrdata_daily = {}\n",
    "\n",
    "print('Computing noise:')\n",
    "for site in hfrsites:\n",
    "    \n",
    "    print('--', site)\n",
    "\n",
    "    # Daily averages\n",
    "    \n",
    "    hfrdata_daily.update({site: hfrdata[site].resample(time='1D').mean()})\n",
    "\n",
    "    hfrdata_daily[site]['nobs'] = hfrdata[site]['nobs'].resample(time='1D').sum()\n",
    "    hfrdata_daily[site]['nobs'].attrs[\"long_name\"] = 'Number of observations'\n",
    "    hfrdata_daily[site]['nobs'].attrs[\"units\"] = 'n/a'    \n",
    "    \n",
    "    # Compute noise\n",
    "    \n",
    "    nobs = hfrdata_daily[site]['nobs'].data\n",
    "    nobs[np.logical_not(np.isfinite(nobs))] = 0\n",
    "    nobs = nobs.astype(int)\n",
    "\n",
    "    ur = hfrdata_daily[site]['VELO'].data\n",
    "    ur = np.ma.array(data=ur, mask=nobs <  1)\n",
    "    \n",
    "    sigma, w1 = hfr_noise(ur, nobs=nobs, return_coeff=True)\n",
    "\n",
    "    # Add to the corresponding dataset\n",
    "\n",
    "    hfrdata_daily[site]['w1'] = xr.zeros_like(hfrdata_daily[site]['VELO'])\n",
    "    hfrdata_daily[site]['w1'].data = w1\n",
    "    hfrdata_daily[site]['w1'].attrs[\"long_name\"] = 'Wavelet coefficents at teh firs scale labeled as noise'\n",
    "    hfrdata_daily[site]['w1'].attrs[\"units\"] = 'cm/s'\n",
    "\n",
    "    hfrdata_daily[site]['sigma'] = xr.DataArray(sigma, dims=('time',))\n",
    "    hfrdata_daily[site]['sigma'].attrs[\"long_name\"] = 'Standard deviation of noise'\n",
    "    hfrdata_daily[site]['sigma'].attrs[\"units\"] = 'cm/s'\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400e3343-29fc-40bc-a201-834dcda1e283",
   "metadata": {},
   "source": [
    "Generate a table with the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c559102a-69b9-4bb3-89c1-8dd96a33f542",
   "metadata": {},
   "outputs": [],
   "source": [
    "for site in hfrsites:\n",
    "\n",
    "    ur = hfrdata[site]['VELO'].data\n",
    "    index = np.isfinite(ur)\n",
    "    mean_ur = np.sqrt(np.mean(ur[index] ** 2))\n",
    "    \n",
    "    sigma = hfrdata_daily[site]['sigma'].data\n",
    "    index = np.isfinite(sigma)\n",
    "    mean_noise = np.mean(sigma[index])\n",
    "    std_noise = np.std(sigma[index])\n",
    "    \n",
    "    formatstr = \"{:} & {:2.1f} & {:.1f} $\\\\pm$ {:.1f} & {:.1f} $\\\\pm$ {:.1f} \\\\\\\\\"\n",
    "    print(formatstr.format(site,\n",
    "                           mean_ur,\n",
    "                           mean_noise, \n",
    "                           std_noise, \n",
    "                           mean_noise * np.sqrt(24), \n",
    "                           std_noise * np.sqrt(24)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ded7781-19e6-4031-a5c9-f7ca6c723f43",
   "metadata": {},
   "source": [
    "Estimate noise using the method described by Kim et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da589a92-af7e-48c7-ae29-e63be5dd0373",
   "metadata": {},
   "outputs": [],
   "source": [
    "hfrnetworks = {}\n",
    "\n",
    "for netwk in networks:\n",
    "\n",
    "    name = '-'.join(netwk)\n",
    "    \n",
    "    # Compute the RMSE from all possible pairs of stations\n",
    "\n",
    "    rmse = np.zeros(0)\n",
    "    angle = np.zeros(0)\n",
    "    \n",
    "    i, j = np.triu_indices(len(netwk), k=1)\n",
    "    for site1, site2 in zip(np.array(netwk)[i],np.array(netwk)[j]):\n",
    "        res = hfr_rmse_pairs(hfrdata[site1], hfrdata[site2], \n",
    "                             maxdist=maxdist, nmin=nmin, rmin=rmin, rmax=rmax)\n",
    "        angle = np.append(angle, res[0])\n",
    "        rmse = np.append(rmse, res[1])\n",
    "    \n",
    "    # Build the output\n",
    "    \n",
    "    hfrnetworks.update({name: {'angle':angle, 'rmse': rmse, 'noise': 0,\n",
    "                              'rmin':rmin, 'rmax':rmax}})\n",
    "\n",
    "    # Fit the RMSE model\n",
    "\n",
    "    angle = np.abs(hfrnetworks[name]['angle'])\n",
    "    rmse = hfrnetworks[name]['rmse']\n",
    "\n",
    "    stdu, stde, cov = hfr_rmse_fit(angle, rmse, stdu=15, stde=8)\n",
    "\n",
    "    hfrnetworks[name].update({'stde':stde, 'stdu':stdu})\n",
    "    \n",
    "    print(name, 'RMSE:',stde, 'cm/s', 'Pairs:', angle.shape[0])\n",
    "\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39888aed-f4b1-4f37-97c6-1bf40617298b",
   "metadata": {},
   "source": [
    "# Figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c922bb4e-08f8-4da8-89d2-9beb92b7d2e9",
   "metadata": {},
   "source": [
    "Create output folder, if it does not exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946eac98-40a4-4d5b-9830-ce87ec0157a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(figspath):\n",
    "    os.mkdir(figspath)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4d8c86-cae8-4418-912c-64f526a7a58f",
   "metadata": {},
   "source": [
    "Plot the general characteristics of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce33bc2-9406-4ac7-8847-c139d35ddd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot limits\n",
    "\n",
    "lonmin = 5\n",
    "lonmax = 0.25\n",
    "latmin = 40\n",
    "latmax = 43.5\n",
    "\n",
    "# Build the plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2 * width, 2 * height), \n",
    "                       subplot_kw=dict(projection=ccrs.PlateCarree()))\n",
    "ax.set_extent([lonmin, lonmax, latmin, latmax], crs=ccrs.PlateCarree())\n",
    "\n",
    "# Add the data\n",
    "\n",
    "for site in hfrsites:\n",
    "\n",
    "    # Get the data\n",
    "    \n",
    "    nr = hfrdata[site].sizes['range']\n",
    "    nb = hfrdata[site].sizes['bearing']\n",
    "\n",
    "    #ur = hfrdata[site].VELO.data\n",
    "    #flag = hfrdata[site].PRIM.data\n",
    "    #range = hfrdata[site].range.data\n",
    "    lon = hfrdata[site].lon.data\n",
    "    lat = hfrdata[site].lat.data\n",
    "    nobs = hfrdata[site].nobs.sum(dim='time').astype(int)\n",
    "\n",
    "    # Fill the map\n",
    "    \n",
    "    for i in np.arange(nb):\n",
    "        index = nobs[:, i] > 1\n",
    "        ax.plot(lon[index, i], lat[index, i], \n",
    "                color=hfrcolors[site], label=site, transform=ccrs.PlateCarree())\n",
    "\n",
    "# Site location\n",
    "\n",
    "for site in hfrsites:\n",
    "\n",
    "    if site == 'CREU' :\n",
    "        dlat = 0\n",
    "        dlon = -0.15\n",
    "    elif site == 'BEGU':\n",
    "        dlat = -0.02\n",
    "        dlon = -0.1\n",
    "    elif site == 'AREN':\n",
    "        dlat = 0.1\n",
    "        dlon = 0\n",
    "    elif site == 'PBCN':\n",
    "        dlat = 0.15\n",
    "        dlon = 0        \n",
    "    elif site == 'GNST':\n",
    "        dlat = 0.05\n",
    "        dlon = -0.07\n",
    "    else:\n",
    "        dlat = 0\n",
    "        dlon = 0\n",
    "\n",
    "    lon0 = hfrdata[site].attrs['lon0']\n",
    "    lat0 = hfrdata[site].attrs['lat0']\n",
    "    \n",
    "    ax.plot(lon0, lat0, 'ko', transform=ccrs.PlateCarree())\n",
    "    ax.text(lon0 + dlon, lat0 + dlat, site, transform=ccrs.PlateCarree(), ha='right', \n",
    "            bbox={'boxstyle':'Round', 'color':hfrcolors[site]})\n",
    "\n",
    "ax.add_feature(land, edgecolor='black')\n",
    "gl = ax.gridlines(draw_labels=True)\n",
    "gl.xlabel_style = {'size': 15}\n",
    "gl.ylabel_style = {'size': 15}\n",
    "gl.top_labels = False\n",
    "gl.right_labels = False\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(figspath + os.sep + 'figure1.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018d103-c18f-4781-a275-9cc0a7628d98",
   "metadata": {},
   "source": [
    "**Figure 1**. Location of the HFR stations used in this study and available radials for each station. The triangle indicates the location of moored current-meter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d275b368-9444-4cdf-b734-58265b6831c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "for site in hfrsites:\n",
    "\n",
    "    # Get the data\n",
    "    \n",
    "    #nr = hfrdata[site].sizes['range']\n",
    "    #nb = hfrdata[site].sizes['bearing']\n",
    "\n",
    "    #ur = hfrdata[site].VELO.data\n",
    "    #flag = hfrdata[site].PRIM.data\n",
    "    range = hfrdata[site].range.data\n",
    "    #lon = hfrdata[site].lon.data\n",
    "    #lat = hfrdata[site].lat.data\n",
    "    nobs = hfrdata[site].nobs.sum(dim='time').astype(int)\n",
    "\n",
    "    # Fill the data distribution\n",
    "\n",
    "    n = np.sum(nobs, axis=-1)\n",
    "    ax.plot(range, n / np.max(n), color=hfrcolors[site], label=site)\n",
    "\n",
    "ax.set_xlabel('$r$ [km]')\n",
    "ax.grid(True, alpha=0.2)\n",
    "ax.set_xticks(np.linspace(0, 120, num=13))\n",
    "ax.set_xlim(0, 120)\n",
    "ax.legend()\n",
    "ax.set_ylabel('$N_{max}^{-1}N_{obs}(r)$')\n",
    "ax.set_yticks(np.linspace(0, 1, num=11))\n",
    "ax.set_ylim(0, 1.1)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(figspath + os.sep + 'figure2.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158cb1fd-8216-4485-9740-c074cc755148",
   "metadata": {},
   "source": [
    "**Figure 2**. Dependence with distance to the antenna of the number of observations divided by its observed maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f44d79-2833-4019-8137-de52d5bfaa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "station = example_stat\n",
    "orientation = 'v'\n",
    "varlist = ['vel', 'num', 'w1']\n",
    "i = iexample\n",
    "\n",
    "# Prepare the data\n",
    "\n",
    "bearing = hfrdata_daily[station]['bearing'].data\n",
    "range = hfrdata_daily[station]['range'].data\n",
    "time = hfrdata_daily[station]['time'][i].data\n",
    "nobs = hfrdata_daily[station]['nobs'][i, :, :].data\n",
    "ur = hfrdata_daily[station]['VELO'][i, :, :].data\n",
    "\n",
    "print(time)\n",
    "\n",
    "# Compute noise. We do not use the noise compute before to ilustrate what happends if the number of\n",
    "# observations are not taken into account\n",
    "\n",
    "ur = np.ma.array(data=ur, mask=nobs < 1)\n",
    "sigma, w1 = hfr_noise(ur, return_coeff=True)\n",
    "\n",
    "# Compute the limits of the plot\n",
    "\n",
    "count = np.sum(nobs, axis=0)\n",
    "minb = np.min(bearing[count > 0])\n",
    "maxb = np.max(bearing[count > 0])\n",
    "\n",
    "# Create the plot\n",
    "\n",
    "nplots = len(varlist)\n",
    "\n",
    "if orientation == 'h':\n",
    "    fig, ax = plt.subplots(1, nplots, figsize=(width * nplots, height))\n",
    "else:\n",
    "    fig, ax = plt.subplots(nplots, 1, figsize=(width, height * nplots))\n",
    "\n",
    "for j, a in enumerate(ax):\n",
    "    a.set_ylim(0, 100)\n",
    "    a.set_xlim(minb, maxb)\n",
    "    if (orientation == 'h' and j == 0) or orientation != 'h':\n",
    "        a.set_ylabel('$r$ [km]')\n",
    "    if (orientation != 'h' and j == nplots - 1) or orientation == 'h':\n",
    "        a.set_xlabel('$\\\\theta$ [deg]')\n",
    "        \n",
    "# Plot the data\n",
    "\n",
    "for j, varname in enumerate(varlist):\n",
    "    if varname == 'vel':\n",
    "        var = ur\n",
    "        title = '$u_r$ [cm/s]'\n",
    "        cmap = 'seismic'\n",
    "        vmax = 50\n",
    "        vmin = - vmax\n",
    "    elif varname == 'num':\n",
    "        var = nobs\n",
    "        title = '$N_{obs}$'\n",
    "        cmap = 'jet'\n",
    "        vmin = 0\n",
    "        vmax = 24\n",
    "    elif varname == 'w1':\n",
    "        var = np.squeeze(w1)\n",
    "        title = '$\\\\sigma_e^{-1} w_1$ [cm/s]'\n",
    "        cmap = 'seismic'\n",
    "        vmin = - 15\n",
    "        vmax = - vmin\n",
    "    else:\n",
    "        var = np.zeros((bearing.shape[0], range.shape[0]))\n",
    "        title = 'unknown'\n",
    "        cmap = None\n",
    "        vmin = None\n",
    "        vmax = None\n",
    "\n",
    "    c = ax[j].pcolormesh(bearing, range, var, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    cb = fig.colorbar(c, ax=ax[j], label=title)\n",
    "    cb.set_label(title, labelpad=0)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(figspath + os.sep + 'figure3.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9304bcc5-58dd-4144-8f93-26779dbc7c3b",
   "metadata": {},
   "source": [
    "**Figure 3** Averaged radial velocities $u_r(r,\\theta)$ over 24h for the GNST station on 2024/01/01 (top); number of averaged data for each range $r$ and bearing $\\theta$ (middle); and wavelet coefficient at scale 1 $w_1(r, \\theta)$ (bottom)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bce78a-1d43-4875-8c47-aea151dd987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(width, height))\n",
    "\n",
    "for site in hfrsites:\n",
    "\n",
    "    # Get the data\n",
    "    \n",
    "    sigma = hfrdata_daily[site]['sigma'].data\n",
    "\n",
    "    # plot\n",
    "\n",
    "    ax.hist(sigma, label=site, bins=150, range=[0, 15], \n",
    "             alpha=0.5, density=True, color=hfrcolors[site])\n",
    "\n",
    "ax.legend()\n",
    "ax.set_xlim(0, 6)\n",
    "ax.set_xlabel('$\\\\sigma_{daily}$ [cm/s]')\n",
    "ax.set_ylabel('PDF')\n",
    "fig.tight_layout()\n",
    "fig.savefig(figspath + os.sep + 'figure4.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58d18539-ed71-402f-af14-01419996cb8b",
   "metadata": {},
   "source": [
    "**Figure 4**. PDF of $\\sigma_{daily}$ for the five HFR stations analyzed. Vertical dashed line corresponds to the estimation of noise obtained using the fitting method for the network AREN-PBCN-GNST and the dotted line the noise obtained with the same method for the network CREU-BEGU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48da1f3c-3022-49c6-a594-166fafaf2960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "orientation = 'v'\n",
    "station = example_stat\n",
    "i = iexample\n",
    "\n",
    "# Create the plot\n",
    "\n",
    "if orientation == 'h':\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(width * 2, height))\n",
    "else:\n",
    "    fig, ax = plt.subplots(2, 1, figsize=(width, 2 * height))\n",
    "\n",
    "x = np.linspace(-3, 3)\n",
    "pdf = np.exp(- x ** 2 / 2) / np.sqrt(2 * np.pi)\n",
    "\n",
    "for j, a in enumerate(ax.flatten()):\n",
    "    \n",
    "    if j == 0:\n",
    "\n",
    "        nobs = hfrdata_daily[station]['nobs'][i, :, :].data   # Read the data\n",
    "        w1 = hfrdata_daily[station]['w1'][i, :, :].data\n",
    "        sigma = hfrdata_daily[station]['sigma'][i].data\n",
    "        data = w1[nobs >= 1] / sigma\n",
    "        \n",
    "        nbins = 50\n",
    "\n",
    "    elif j == 1:\n",
    "\n",
    "        data = data=np.zeros(0)\n",
    "        for key in hfrdata_daily.keys():\n",
    "            nobs = hfrdata_daily[key]['nobs'].data   # Read the data\n",
    "            w1 = hfrdata_daily[key]['w1'].data\n",
    "            sigma = hfrdata_daily[key]['sigma'].data\n",
    "            w1 = w1 / sigma[:, np.newaxis, np.newaxis] # Normalize \n",
    "            data = np.append(data, w1[nobs >= 1])\n",
    "\n",
    "        nbins = 300\n",
    "\n",
    "    a.hist(data, bins=nbins, range=[-3, 3], density=True, color='gray')\n",
    "    a.plot(x, pdf, color='k')\n",
    "\n",
    "for j, a in enumerate(ax):\n",
    "    a.set_xlim(-3, 3)\n",
    "    a.set_ylim(0, 0.6)\n",
    "    if (orientation == 'h' and j == 0) or orientation != 'h':\n",
    "        a.set_ylabel('PDF')\n",
    "    if (orientation != 'h' and j == 1) or orientation == 'h':\n",
    "        a.set_xlabel('$w_1^{*(n)} \\\\sigma_1^{e-1} \\\\sigma_{daily}^{-1}$')\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig('figures/figure5.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f443475-adfd-4f15-a235-f24243e66d5e",
   "metadata": {},
   "source": [
    "**Figure 5**. Probability Density Functions (PDF) for the corrected noisy wavelet coefficients for the example shown in Figure 3 (top) and for the whole time series (bottom). Coefficients are normalized by the noise standard deviation. The solid line corresponds to a Normal distribution with unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c9718b-4e26-4683-9e6c-32e1865e49dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "nplots = len(hfrnetworks.keys())\n",
    "\n",
    "fig, ax = plt.subplots(nplots, 1, figsize=(width, height * nplots))\n",
    "for i, name in enumerate(hfrnetworks.keys()):\n",
    "    \n",
    "    angle = np.abs(hfrnetworks[name]['angle'])\n",
    "    rmse = hfrnetworks[name]['rmse']\n",
    "    stdu = hfrnetworks[name]['stdu']\n",
    "    stde = hfrnetworks[name]['stde']\n",
    "\n",
    "    ax[i].plot(angle, rmse, 'k.', label='Observations')\n",
    "    \n",
    "    angle = np.linspace(0, 360)\n",
    "    ax[i].plot(angle, hfr_rmse_model(angle, stdu, stde), 'k--', label='Model')\n",
    "\n",
    "    ax[i].set_title(name)\n",
    "    ax[i].set_xlim(0, 360)\n",
    "    ax[i].set_ylim(0, 50)\n",
    "    ax[i].set_ylabel('$\\\\sigma_{rms}$ [cm/s]')\n",
    "    if i == nplots-1:\n",
    "        ax[i].set_xlabel('$\\\\theta_A-\\\\theta_B$ [deg]')\n",
    "    ax[i].legend()\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(figspath + os.sep + 'figure6.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45e0331-2b53-43ea-8f07-11d13aeb8a51",
   "metadata": {},
   "source": [
    "**Figure 6** Observed RMSE $\\sigma_{rms}$ at crossover points for the two subnetworks with the fitted model of RMSE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514bd9aa-82be-4f1d-8aa9-e14fc5a716d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize=(10, 2 * height))\n",
    "\n",
    "tmin = []\n",
    "tmax = []\n",
    "\n",
    "for site in hfrsites:\n",
    "\n",
    "    # Get the data\n",
    "    \n",
    "    sigma = hfrdata_daily[site]['sigma'].data\n",
    "    time = hfrdata_daily[site]['time'].data\n",
    "\n",
    "    nobs = np.sum(hfrdata_daily[site]['nobs'].data, axis=(1, 2))\n",
    "\n",
    "    tmin.append(np.min(time))\n",
    "    tmax.append(np.max(time))\n",
    "    \n",
    "    # Plot\n",
    "\n",
    "    ax[0].plot(time, sigma, color=hfrcolors[site], label=site)\n",
    "\n",
    "    if site == 'CREU':\n",
    "        ax[1].plot(time, nobs/np.max(nobs), color=hfrcolors[site], label=site)\n",
    "\n",
    "tmin = np.min(np.array(tmin))\n",
    "tmax = np.max(np.array(tmax))\n",
    "\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel('$\\\\sigma_{daily}(t)$ [cm/s]')\n",
    "ax[0].set_ylim(1, 5)\n",
    "ax[0].set_xlim(tmin, tmax)\n",
    "\n",
    "ax[1].legend()\n",
    "ax[1].set_ylabel('$N_{max}^{-1}N_{obs}(t)$')\n",
    "ax[1].set_xlim(tmin, tmax)\n",
    "#ax[1].axvspan(np.datetime64(\"2024-06-01\"), np.datetime64(\"2025-01-28\"), color='r', alpha=0.1)\n",
    "ax[1].axvline(np.datetime64(\"2025-01-28\"), color='k',linestyle='--')\n",
    "ax[1].set_ylim(0, 1)\n",
    "\n",
    "fig.tight_layout()\n",
    "fig.savefig(figspath + os.sep + 'figure7.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a46d88c-9c61-4f00-a4f6-f3488731a046",
   "metadata": {},
   "source": [
    "**Figure 7**. Time evolution of the noise level (top) and number of observations divided by its observed maximum for the CREU station (bottom). The dashed line in the bottom plot corresponds to the date of the antenna repair (January 28 2025)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79b063c-bffa-4142-a3b1-c65d4162f951",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(10, height))\n",
    "\n",
    "tmin = []\n",
    "tmax = []\n",
    "\n",
    "for site in hfrsites:\n",
    "\n",
    "    # Get the data\n",
    "    \n",
    "    sigma = hfrdata_daily[site]['sigma'].data\n",
    "    time = hfrdata_daily[site]['time'].data\n",
    "\n",
    "    tmin.append(np.min(time))\n",
    "    tmax.append(np.max(time))\n",
    "    \n",
    "    # Plot\n",
    "\n",
    "    ax.plot(time, np.sqrt(24) * sigma, color=hfrcolors[site], label=site)\n",
    "\n",
    "tmin = np.min(np.array(tmin))\n",
    "tmax = np.max(np.array(tmax))\n",
    "\n",
    "ax.legend()\n",
    "ax.set_ylabel('$\\\\sigma_{hourly}$ [cm/s]')\n",
    "ax.set_ylim(5, 25)\n",
    "ax.set_xlim(tmin, tmax)\n",
    "\n",
    "fig.tight_layout()\n",
    "#fig.savefig('figures/fig_noise_time_series.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e52f460-eefe-48f3-a212-69e1cd018fca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
